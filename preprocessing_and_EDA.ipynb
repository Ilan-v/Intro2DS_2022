{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Lior Tondovski, Ilan Vasilevski, Maya Vilenko"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.utils import resample\n",
    "# import smote\n",
    "from imblearn.over_sampling import SMOTE\n",
    "#inport stadard scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from utils import *\n",
    "from Config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data\n",
    "train_data = pd.read_csv(training_data_path)\n",
    "test_data = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data shape\n",
    "print(f'the shape of the train_data is {train_data.shape}')\n",
    "print(f'the shape of the test_data is {test_data.shape}')\n",
    "print(f'the ratio between the train and test data is {round(test_data.shape[0]/train_data.shape[0], 2)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check unique values in each column\n",
    "train_data.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be seen for example that resolution column has a single value so it doesnt add any information and we will remove it in the preprocess phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data types\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bat chart of clicked ratio per state\n",
    "#first we need to group the data by state and count the number of clicks\n",
    "state_clicks = train_data.groupby('state')['clicked'].mean().reset_index()\n",
    "state_clicks = state_clicks.sort_values(by='clicked', ascending=False)\n",
    "\n",
    "#plot the data\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='state', y='clicked', data=state_clicks)\n",
    "plt.title('Clicked ratio per state', fontsize=20)\n",
    "plt.xlabel('State', fontsize=15)\n",
    "plt.ylabel('Clicked ratio', fontsize=15)\n",
    "#rotate the x labels\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much variation in the click ratio between the countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot click ratio per app category\n",
    "#first we need to group the data by app category and count the number of clicks\n",
    "app_clicks = train_data.groupby('app_cat')['clicked'].mean().reset_index()\n",
    "app_clicks = app_clicks.sort_values(by='clicked', ascending=False)\n",
    "\n",
    "#plot the data\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='app_cat', y='clicked', data=app_clicks)\n",
    "plt.title('Clicked ratio per app category', fontsize=20)\n",
    "plt.xlabel('App category', fontsize=15)\n",
    "plt.ylabel('Clicked ratio', fontsize=15)\n",
    "#rotate the x labels\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph shows that click ratios are pretty varied between categories of applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot click ratio per the location of the add\n",
    "#first we need to group the data by location and count the number of clicks\n",
    "location_clicks = train_data.groupby('banner_pos')['clicked'].mean().reset_index()\n",
    "location_clicks = location_clicks.sort_values(by='clicked', ascending=False)\n",
    "\n",
    "#plot the data\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.barplot(x='banner_pos', y='clicked', data=location_clicks)\n",
    "plt.title('Clicked ratio per location', fontsize=20)\n",
    "plt.xlabel('Location', fontsize=15)\n",
    "plt.ylabel('Clicked ratio', fontsize=15)\n",
    "#rotate the x labels\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this graph, adds on the bottom/right of the screen are less likely to be clicked!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_missing_values = check_missing_values(train_data)\n",
    "test_data_missing_values = check_missing_values(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing values in the train data\n",
    "train_data_missing_values[train_data_missing_values['missing_values_percentage']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check the missing values in the test data\n",
    "test_data_missing_values[test_data_missing_values['missing_values_percentage']>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace missing values with the category 'unknown'\n",
    "#the reason that we replace the missing values with the category 'unknown' is because we want to keep the information that the value is missing\n",
    "train_data = replace_missing_values(train_data)\n",
    "test_data = replace_missing_values(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preprocess & Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding for app_category, banner_pos, device_version, state\n",
    "get_dummis = ['state','manufacturer', 'app_cat', 'banner_pos', 'device_version']\n",
    "train_data = pd.get_dummies(train_data, columns=get_dummis, prefix=get_dummis)\n",
    "test_data = pd.get_dummies(test_data, columns=get_dummis, prefix=get_dummis)\n",
    "\n",
    "#op_id colums assigns unique id to each row and it is not useful for our model\n",
    "train_data.drop(columns=['op_id'], inplace=True)\n",
    "test_data.drop(columns=['op_id'], inplace=True)\n",
    "\n",
    "#drop app_id column due to the high cardinality\n",
    "train_data.drop(columns=['app_id'], inplace=True)\n",
    "test_data.drop(columns=['app_id'], inplace=True)\n",
    "\n",
    "#drop resolution column due single value\n",
    "train_data.drop(columns=['resolution'], inplace=True)\n",
    "test_data.drop(columns=['resolution'], inplace=True)\n",
    "\n",
    "#change the target variable to binary feature\n",
    "train_data['clicked'] = train_data['clicked'].apply(lambda x: 1 if x == True else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract new features from the categorical features and drop the original features\n",
    "#The features are the ratio of the number of clicks for each category in each feature\n",
    "categorical_columns = ['user_isp', 'device_model']\n",
    "new_feature_names = ['user_isp_ratio_clicked', 'device_mode_ratio_clicked']\n",
    "train_data, test_data = check_the_ratio_of_clicked_from_feature(train_data, test_data, categorical_columns, new_feature_names)\n",
    "#drop the original features\n",
    "train_data.drop(columns=['user_isp', 'device_model'], inplace=True)\n",
    "test_data.drop(columns=['user_isp', 'device_model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new features from the timestamp - day, month, year, hour\n",
    "#chenge timestamp to datetime\n",
    "train_data['timestamp'] = pd.to_datetime(train_data['timestamp'])\n",
    "test_data['timestamp'] = pd.to_datetime(test_data['timestamp'])\n",
    "#extract hour, day, month, year from timestamp\n",
    "train_data['hour'] = train_data['timestamp'].dt.hour\n",
    "train_data['day'] = train_data['timestamp'].dt.day\n",
    "train_data['month'] = train_data['timestamp'].dt.month\n",
    "train_data['year'] = train_data['timestamp'].dt.year\n",
    "\n",
    "test_data['hour'] = test_data['timestamp'].dt.hour\n",
    "test_data['day'] = test_data['timestamp'].dt.day\n",
    "test_data['month'] = test_data['timestamp'].dt.month\n",
    "test_data['year'] = test_data['timestamp'].dt.year\n",
    "#drop timestamp\n",
    "train_data.drop(columns=['timestamp'], inplace=True)\n",
    "test_data.drop(columns=['timestamp'], inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target Varible Distributin - Check if the Data is Balanced or Not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the data is balanced\n",
    "print(f'number of negative samples {train_data[train_data.clicked == 0].shape[0]}')\n",
    "print(f'number of positive samples {train_data[train_data.clicked == 1].shape[0]}')\n",
    "print(f'The ratio of negative samples to positive samples is {(train_data[train_data.clicked == 0].shape[0] / train_data.shape[0])*100:.2f}%')\n",
    "print(f'The ratio of positive samples to negative samples is {(train_data[train_data.clicked == 1].shape[0] / train_data.shape[0])*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the distribution of the target variable\n",
    "sns.countplot(x='clicked', data=train_data)\n",
    "plt.legend(['Not clicked', 'Clicked'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is completely unbalanced, as can be seen!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Because the there are many features, we will plot only the features with the highest correlation with the target variable\n",
    "#find the correlation between the features and the target variable\n",
    "correlation = train_data.corr()\n",
    "correlation = correlation.sort_values(by='clicked', ascending=False)\n",
    "#most correlated features with the target variable\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(correlation.head(10)[list(correlation.head(10).index.values)], annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation matrix of the features with the highest correlation with the target variable', fontsize=20)\n",
    "plt.xlabel('Features', fontsize=15)\n",
    "plt.ylabel('Features', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove highly correlated features\n",
    "features=[x for x in train_data.columns if x not in ['clicked']]\n",
    "\n",
    "to_drop = drop_correlated_features(corr_threshold=0.9, data=train_data[features])\n",
    "\n",
    "train_data.drop(columns=to_drop, inplace=True)\n",
    "test_data.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Standartization Before SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize the numerical features\n",
    "columns_to_standardize = [x for x in train_data.columns if x not in binary_columns]\n",
    "#standardize the train data with standard scaler\n",
    "scaler = StandardScaler()\n",
    "train_data[columns_to_standardize] = scaler.fit_transform(train_data[columns_to_standardize])\n",
    "#standardize the test data with standard scaler\n",
    "test_data[columns_to_standardize] = scaler.transform(test_data[columns_to_standardize])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#undersample the data with sklearn\n",
    "# Separate majority and minority classes\n",
    "train_data_majority = train_data[train_data.clicked==0]\n",
    "train_data_minority = train_data[train_data.clicked==1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(train_data_majority,\n",
    "                                    replace=False,    # sample without replacement\n",
    "                                    n_samples=train_data_minority.shape[0]*5,     # The majority class will be downsampled to the size of the minority class * 5\n",
    "                                    random_state=12) # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "train_data_under_sampled = pd.concat([df_majority_downsampled, train_data_minority])\n",
    "# Display new class counts\n",
    "print(train_data_under_sampled.clicked.value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply smote on train_data_under_sampled\n",
    "sm = SMOTE(random_state=12, sampling_strategy=0.5)\n",
    "X_train_sm, y_train_sm = sm.fit_resample(train_data_under_sampled.drop(columns=['clicked']), train_data_under_sampled.clicked)\n",
    "#convert the data to pandas dataframe\n",
    "X_train_sm = pd.DataFrame(X_train_sm, columns=train_data_under_sampled.drop(columns=['clicked']).columns)\n",
    "y_train_sm = pd.DataFrame(y_train_sm, columns=['clicked'])\n",
    "\n",
    "#combine the data\n",
    "train_data_under_sampled_sm = pd.concat([X_train_sm, y_train_sm], axis=1)\n",
    "\n",
    "#distribution of the target variable\n",
    "train_data_under_sampled_sm['clicked'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save Train and Test Sets (After Undersampling & With or Without Smote Oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the train and test data into pickle files\n",
    "train_data_under_sampled.to_pickle('processed_train_data_undersampled.pkl')\n",
    "train_data_under_sampled_sm.to_pickle('processed_train_data_undersampled_sm.pkl')\n",
    "test_data.to_pickle('processed_test_data.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0162daef2ac4f91d71dc659d7366b1318efa6dce3a9605ecac659f5b282e8a3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
