{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors: Lior Tondovski, Ilan Vasilevski, Maya Vilenko"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "#visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "#preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.stats import shapiro\n",
    "#clasiifiers\n",
    "from xgboost import XGBClassifier\n",
    "#Dimensionality reduction\n",
    "from sklearn.decomposition import PCA\n",
    "#Anomaly detection\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import RFECV\n",
    "#Hyperparameter tuning\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "#metrics and model evaluation\n",
    "import shap\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "#utils\n",
    "from utils import *\n",
    "#config\n",
    "from Config import *\n",
    "#set seed\n",
    "np.random.seed(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\liort\\OneDrive\\שולחן העבודה\\Exercise\\training_and_evaluation.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liort/OneDrive/%D7%A9%D7%95%D7%9C%D7%97%D7%9F%20%D7%94%D7%A2%D7%91%D7%95%D7%93%D7%94/Exercise/training_and_evaluation.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#read train and test data pickls\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/liort/OneDrive/%D7%A9%D7%95%D7%9C%D7%97%D7%9F%20%D7%94%D7%A2%D7%91%D7%95%D7%93%D7%94/Exercise/training_and_evaluation.ipynb#Y102sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39mprocessed_test_data.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liort/OneDrive/%D7%A9%D7%95%D7%9C%D7%97%D7%9F%20%D7%94%D7%A2%D7%91%D7%95%D7%93%D7%94/Exercise/training_and_evaluation.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_undersampled_sm \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39mprocessed_train_data_undersampled_sm.pkl\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/liort/OneDrive/%D7%A9%D7%95%D7%9C%D7%97%D7%9F%20%D7%94%D7%A2%D7%91%D7%95%D7%93%D7%94/Exercise/training_and_evaluation.ipynb#Y102sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_oversampled\u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_pickle(\u001b[39m'\u001b[39m\u001b[39mprocessed_train_data_undersampled.pkl.pkl\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#read train and test data pickls\n",
    "test = pd.read_pickle('processed_test_data.pkl')\n",
    "train_undersampled_sm = pd.read_pickle('processed_train_data_undersampled_sm.pkl')\n",
    "train_oversampled= pd.read_pickle('processed_train_data_undersampled.pkl.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Test Split\n",
    "Train, Test = train_test_split(train_data, test_size=0.2, random_state=42)\n",
    "X_train = Train[all_features]\n",
    "y_train = Train[target_column].squeeze()\n",
    "X_test = Test[all_features]\n",
    "y_test = Test[target_column].squeeze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: Based on the PCA dimension reduction to 3 Dimension, it can be observed that the data is fairly linearly separated, which is why it should perform well on the evaluation metrics once a classifier is fitted to make a prediction. Over 95% of the variance is preserved by three PCA components."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection using RFE\n",
    "#RFECV is a recursive feature elimination with cross validation\n",
    "xgb_classifier = XGBClassifier()\n",
    "rfecv = RFECV(estimator=xgb_classifier, step=1, cv=5, scoring='roc_auc')\n",
    "rfecv.fit(X_train, y_train)\n",
    "print(f'Optimal number of features : {rfecv.n_features_}')\n",
    "print(f'Best features : {X_train.columns[rfecv.support_]}')\n",
    "\n",
    "#plot the average cross validation score for each number of features\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.title('Recursive Feature Elimination with Cross-Validation')\n",
    "plt.xlabel('Number of features selected')\n",
    "plt.ylabel(' Abveraged Cross validation score ')\n",
    "#calc the average cross validation score for each number of features\n",
    "avrage_cv_scores = [np.mean(cv_scores) for cv_scores in rfecv.grid_scores_]\n",
    "plt.plot(range(1, len(avrage_cv_scores) + 1), avrage_cv_scores)\n",
    "#add grid\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep the best features\n",
    "X_train = X_train[X_train.columns[rfecv.support_]]\n",
    "X_test = X_test[X_test.columns[rfecv.support_]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameter Tuning with Skopt BayesSearchCV (Bayesian Optimization)\n",
    "#Bayesian Optimization is a method for optimizing an expensive function by iteratively building a surrogate function that approximates the function being optimized\n",
    "#set the classifier\n",
    "xgb_classifier = XGBClassifier()\n",
    "#set the parameters to search for\n",
    "params = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'max_depth': Integer(3, 10),\n",
    "    'learning_rate': Real(0.01, 1.0, 'log-uniform'),\n",
    "    'subsample': Real(0.01, 1.0, 'uniform'),\n",
    "    'colsample_bytree': Real(0.01, 1.0, 'uniform'),\n",
    "    'min_child_weight': Integer(1, 10),\n",
    "    'gamma': Real(0.0, 50.0, 'uniform'),\n",
    "    'reg_alpha': Real(0.0, 50.0, 'uniform'),\n",
    "    'reg_lambda': Real(0.0, 50.0, 'uniform'),\n",
    "    'scale_pos_weight': Real(0.01, 50.0, 'uniform'),\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "#set the bayes search cv\n",
    "opt = BayesSearchCV(\n",
    "    xgb_classifier,\n",
    "    params,\n",
    "    n_iter=50,\n",
    "    scoring='roc_auc',\n",
    "    cv=2,\n",
    "    n_jobs=-1,\n",
    "    verbose=0,\n",
    "    refit=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "#fit the model\n",
    "opt.fit(X_train, y_train)\n",
    "#print the best parameters\n",
    "print(f'the best parameters are: {opt.best_params_}')\n",
    "#print the best score\n",
    "print(f'the best auc score: {opt.best_score_}')\n",
    "#save the best estimator\n",
    "best_estimator = opt.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After Further analysis of the differances between the train and test set we found that the train set overfits a bit\n",
    "# and thefore i decided to increase the gamma parameter which is responsible for the tree pruning and will reduce the overfitting\n",
    "best_estimator.set_params(gamma=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature importance with SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the feature importance with shap values\n",
    "explainer = shap.TreeExplainer(best_estimator)\n",
    "#calculate the shap values\n",
    "shap_values = explainer.shap_values(X_train)\n",
    "#plot shap bar plot\n",
    "shap.summary_plot(shap_values, X_train, plot_type='bar')\n",
    "#plot shap beeswarm\n",
    "shap.summary_plot(shap_values, X_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion: ....."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test set - predictions and evaluation\n",
    "y_pred = best_estimator.predict(X_test)\n",
    "y_pred_proba = best_estimator.predict_proba(X_test)[:,1]\n",
    "\n",
    "#calculate the accuracy score\n",
    "print(f'Accuracy Score : {accuracy_score(y_test, y_pred)}')\n",
    "#calculate the precision score\n",
    "print(f'Precision Score : {precision_score(y_test, y_pred)}')\n",
    "#calculate the recall score\n",
    "print(f'Recall Score : {recall_score(y_test, y_pred)}')\n",
    "#calculate the f1 score\n",
    "print(f'F1 Score : {f1_score(y_test, y_pred)}')\n",
    "#calculate auc\n",
    "print(f'AUC : {roc_auc_score(y_test, y_pred_proba)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ROC curve\n",
    "plot_roc_curve(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the precision recall curve\n",
    "plot_precision_recall_curve(y_test, y_pred_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the confusion matrix\n",
    "plot_confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check if the model is overfitting\n",
    "#compare the train and test scores\n",
    "plot_comparison_bar_chart(best_estimator, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0162daef2ac4f91d71dc659d7366b1318efa6dce3a9605ecac659f5b282e8a3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
